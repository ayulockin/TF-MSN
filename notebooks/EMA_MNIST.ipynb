{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EMA MNIST",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN+uOFczMVjBSgj5F1yMDDo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayulockin/TF-MSN/blob/main/notebooks/EMA_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq wandb"
      ],
      "metadata": {
        "id": "a4Pk-0yb4wpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dew-w8qVR4pq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_imgs, train_labels = x_train[:1000], y_train[:1000]\n",
        "valid_imgs, valid_labels = x_train[1000:1100], y_train[1000:1100]\n",
        "\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "def preprocess_image(image, label):\n",
        "    img = tf.cast(image, tf.float32)\n",
        "    img = img/255.\n",
        "\n",
        "    return img, label\n",
        "\n",
        "trainloader = tf.data.Dataset.from_tensor_slices((train_imgs, train_labels))\n",
        "validloader = tf.data.Dataset.from_tensor_slices((valid_imgs, valid_labels))\n",
        "\n",
        "trainloader = (\n",
        "    trainloader\n",
        "    .shuffle(1024)\n",
        "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")\n",
        "\n",
        "validloader = (\n",
        "    validloader\n",
        "    .map(preprocess_image, num_parallel_calls=AUTO)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(AUTO)\n",
        ")"
      ],
      "metadata": {
        "id": "ThQoKyd2YiqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_anchor_model():\n",
        "    inputs = layers.Input(shape=(28, 28, 1))\n",
        "    x = layers.Conv2D(3, 3, activation=\"relu\")(inputs)\n",
        "    x = layers.Conv2D(3, 3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.Conv2D(3, 3, activation=\"relu\")(x)\n",
        "    x = layers.Conv2D(3, 3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    \n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    x = layers.Dense(64)(x)\n",
        "    classifier = layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "    return models.Model(inputs, classifier, name=\"anchor_model\")\n",
        "\n",
        "def build_target_model():\n",
        "    inputs = layers.Input(shape=(28, 28, 1))\n",
        "    x = layers.Conv2D(3, 3, activation=\"relu\")(inputs)\n",
        "    x = layers.Conv2D(3, 3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = layers.Conv2D(3, 3, activation=\"relu\")(x)\n",
        "    x = layers.Conv2D(3, 3, activation=\"relu\")(x)\n",
        "    x = layers.MaxPooling2D()(x)\n",
        "    \n",
        "    x = layers.GlobalAvgPool2D()(x)\n",
        "    x = layers.Dense(64)(x)\n",
        "    classifier = layers.Dense(10, activation=\"softmax\")(x)\n",
        "\n",
        "    return models.Model(inputs, classifier, name=\"target_model\")"
      ],
      "metadata": {
        "id": "xS_0Is9O1ksX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "anchor_model = build_anchor_model()\n",
        "anchor_model.summary()"
      ],
      "metadata": {
        "id": "xMMWuLdj2r01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "target_model = build_target_model()\n",
        "target_model.summary()"
      ],
      "metadata": {
        "id": "K27k56un2rr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def siamese_network():\n",
        "    inputs = layers.Input(shape=(28,28,1))\n",
        "    # Init anchor model\n",
        "    anchor_model = build_anchor_model()\n",
        "    # Init target model without trainable params.\n",
        "    target_model = build_target_model()\n",
        "    target_model.trainable = False\n",
        "\n",
        "    z1 = anchor_model(inputs)\n",
        "    z2 = target_model(inputs)\n",
        "\n",
        "    return models.Model(inputs, outputs=[z1, z2])"
      ],
      "metadata": {
        "id": "8z1JOgQu2x_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Without EMA"
      ],
      "metadata": {
        "id": "rC8KDm7v4LG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init()\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model = siamese_network()\n",
        "model.summary(expand_nested=False)\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss={\n",
        "        'anchor_model': 'sparse_categorical_crossentropy',\n",
        "        'target_model': 'sparse_categorical_crossentropy'\n",
        "    },\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(trainloader, validation_data=validloader, epochs=100, callbacks=[WandbCallback(save_model=False)])\n",
        "\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "lbOy10A127O3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With EMA"
      ],
      "metadata": {
        "id": "VXKc1cv94QYE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EMA(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, decay=0.999):\n",
        "        super(EMA, self).__init__()\n",
        "        self.decay = decay\n",
        "\n",
        "        # Create an ExponentialMovingAverage object\n",
        "        self.ema = tf.train.ExponentialMovingAverage(decay=self.decay)\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.ema.apply(self.model.get_layer('anchor_model').trainable_variables)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Get exponential moving average of anchor model weights.\n",
        "        train_vars = self.model.get_layer('anchor_model').trainable_variables\n",
        "        averages = [self.ema.average(var) for var in train_vars]\n",
        "\n",
        "        # Assign the average weights to target model\n",
        "        target_model_vars = self.model.get_layer('target_model').non_trainable_variables\n",
        "        assert len(target_model_vars) == len(averages)\n",
        "        for i, var in enumerate(target_model_vars):\n",
        "            var.assign(averages[i])\n",
        "\n",
        "        self.ema.apply(self.model.get_layer('anchor_model').trainable_variables)"
      ],
      "metadata": {
        "id": "QbL5HdXe27GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init()\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model = siamese_network()\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss={\n",
        "        'anchor_model': 'sparse_categorical_crossentropy',\n",
        "        'target_model': 'sparse_categorical_crossentropy'\n",
        "    },\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(trainloader, validation_data=validloader, epochs=100, callbacks=[EMA(), WandbCallback(save_model=False)])\n",
        "\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "KT2QZHSv3qYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zeQqyaRfXh7h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}